{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re\n",
    "from time import time, sleep\n",
    "import sys\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter\n",
    "\n",
    "sys.path.append('../src/')\n",
    "# from summarizer import get_transcript\n",
    "# from summarizer import gpt3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../src/'\n",
    "# video_id = '0lJKucu6HJc'\n",
    "# video_id = 'uh1GRQtKjLo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(content, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "    if not video_id:\n",
    "        raise Exception('Video ID not found')\n",
    "\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "\n",
    "        formatter = JSONFormatter()\n",
    "        text = formatter.format_transcript(transcript)\n",
    "        # text = re.sub('\\s+', ' ', text).replace('--', '')\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception('Could not download the transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_transcript(transcript, end, start=0):             # example: start | end = 652 (seconds)\n",
    "    if start > end[0]: raise Exception('Start is ahead of End')\n",
    "\n",
    "    text = []\n",
    "    for obj in transcript:\n",
    "        if start > obj['start']: continue\n",
    "        if obj['start'] > end:\n",
    "            return re.sub('\\s+', ' ', ' '.join(text))\n",
    "        text.append(obj['text'])\n",
    "\n",
    "\n",
    "def slice_transcript(transcript, end=list(), start=list()):     # example: end=list[34.56, 66.45]; start=65.32 (seconds)\n",
    "    if not len(end): raise Exception('Missing parameter: end')\n",
    "    if start[0] > end[0]: raise Exception('Start is ahead of End')\n",
    "\n",
    "    chapters = []\n",
    "    text = []\n",
    "    checkpoint = 0\n",
    "    for obj in transcript:\n",
    "        if start[0] > obj['start']: continue\n",
    "        if checkpoint >= len(end): return chapters\n",
    "\n",
    "        if obj['start'] > end[checkpoint]:\n",
    "            chapters.append((start[checkpoint], re.sub('\\s+', ' ', ' '.join(text))))\n",
    "            text.clear()\n",
    "            checkpoint += 1\n",
    "        text.append(obj['text'])\n",
    "\n",
    "    return chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(time_str):\n",
    "    parts = [int(part) for part in time_str.split(\":\")]\n",
    "    if len(parts) == 2:\n",
    "        return parts[0] * 60 + parts[1]\n",
    "    elif len(parts) == 3:\n",
    "        return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid time format: \" + time_str)\n",
    "\n",
    "def transform_chapter_timestamp(chapters):\n",
    "    '''\n",
    "    This function expects chapter with timestamp as string. The last item should be the 'End' timestamp, indicating the end of the video.\n",
    "        [\"00:00 Chapter Title\"]\n",
    "        [\"04:15 Chapter Title\"]\n",
    "        [\"07:21 Chapter Title\"]\n",
    "        [\"10:31 End\"]\n",
    "    '''\n",
    "\n",
    "    chapter_list = [line.strip().split(\" \", 1) for line in chapters]\n",
    "\n",
    "    # chapter titles\n",
    "    chapter_titles = [chapter[1] for chapter in chapter_list]\n",
    "\n",
    "    # chapter start ts\n",
    "    chapter_starts = []\n",
    "    for chapter in chapter_list:\n",
    "        if chapter[0][0].isdigit():\n",
    "            chapter_starts.append(time_to_seconds(chapter[0]))\n",
    "        else:\n",
    "            chapter_starts.append(time_to_seconds(chapter[0][1:-1]))\n",
    "\n",
    "    # chapter end & start ts\n",
    "    chapter_ends = chapter_starts[1:]\n",
    "    chapter_starts = chapter_starts[:-1]    # exclude the 'End' timestamp\n",
    "\n",
    "    return list(zip(chapter_starts, chapter_ends, chapter_titles))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'FOuks3BM55o'\n",
    "\n",
    "chapters = '''\n",
    "(0:00) Bestie intros!\n",
    "(6:47) The VC FOMO frenzy in AI\n",
    "(25:22) Current LP mindset, VCs leaving boards, startup cram downs and mark downs\n",
    "(37:23) Macro update: inflation not done, weaker earnings, interest rates\n",
    "(52:01) Marc Benioff channels his inner Elon Musk, the stock-based compensation boom\n",
    "(1:11:59) Fox News facing defamation lawsuit over false election fraud claims, TikTok ban heats up, competition with China\n",
    "(1:34:33) Ukraine update: China's peace proposal, US strategy\n",
    "(1:46:34) Harvard legacy admissions, Draymond Green on Black History Month\n",
    "(1:50:01) End\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_list = chapters.strip().split(\"\\n\")\n",
    "chapter_ts = transform_chapter_timestamp(chapter_list)\n",
    "\n",
    "ch_starts = [ch[0] for ch in chapter_ts]\n",
    "ch_ends = [ch[1] for ch in chapter_ts]\n",
    "print('start:', ch_starts, 'end:', ch_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download transcript\n",
    "transcript = json.loads(get_transcript(video_id))\n",
    "save_file(json.dumps(transcript), f'./chapters/transcript_{video_id}.txt')\n",
    "\n",
    "# multiple slice\n",
    "transcripts = slice_transcript(transcript, ch_ends, ch_starts)\n",
    "\n",
    "for chapter in transcripts:\n",
    "    prompt = open_file('prompt_chapter_summary.txt').replace('<<TEXT>>', chapter[1])\n",
    "    save_file(prompt, f'./chapters/chapter_{video_id}_{chapter[0]}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3hustlers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d73ac72d0a6cdf376a9fb76a0a75bf4f8e4342cbea816d6b606bcc262c107652"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
